{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzM39wB1U5e8",
        "outputId": "2fdbd996-f984-447f-a39b-de81a219a8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "scaler-item <built-in method item of Tensor object at 0x7dc413b006b0>\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "torch.Size([3, 3])\n",
            "tensor([[ 1,  2,  3,  4],\n",
            "        [ 5,  6,  7,  8],\n",
            "        [ 9, 10, 11, 12]])\n",
            "torch.Size([3, 4])\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([[[ 1,  2,  3,  4],\n",
            "         [ 5,  6,  7,  8],\n",
            "         [ 9, 10, 11, 12]]])\n",
            "tensor([[0.7141, 0.1856, 0.1389, 0.6982],\n",
            "        [0.5941, 0.9938, 0.3335, 0.6462],\n",
            "        [0.0442, 0.7029, 0.3211, 0.0397]])\n",
            "tensor(55.)\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-42-1899087670.py:51: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  t_range=tr.range(0,10);\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import torch as tr;\n",
        "from tr import nn;\n",
        "import numpy as np\n",
        "import pandas as pd;\n",
        "import matplotlib.pyplot as plt;\n",
        "import seaborn as sns;\n",
        "'''\n",
        "Abu Al Shahriar Rifat\n",
        "Bsc in IT,Sharda University,India,\n",
        "Msc in Transpotation Engineering,Hohai University,China\n",
        "'''\n",
        "\n",
        "##Scaler\n",
        "scaler=tr.tensor(7);\n",
        "print(scaler.ndim)\n",
        "print(\"scaler-item\",scaler.item)\n",
        "vector=tr.tensor(\n",
        "    [[1,2,3],\n",
        "    [4,5,6],\n",
        "    [7,8,9]]\n",
        ")\n",
        "print(vector)\n",
        "print(vector.shape)\n",
        "##Matrix\n",
        "matrix=tr.tensor(\n",
        "    [\n",
        "    [1,2,3,4],\n",
        "    [5,6,7,8],\n",
        "    [9,10,11,12]\n",
        "    ]\n",
        ")\n",
        "print(matrix)\n",
        "print(matrix.shape);\n",
        "print(matrix[0])\n",
        "#####################Tensor##############\n",
        "tensor=tr.tensor([[\n",
        "    [1,2,3,4],\n",
        "    [5,6,7,8],\n",
        "    [9,10,11,12]\n",
        "]])\n",
        "print(tensor)\n",
        "\n",
        "\n",
        "###Random tensor####\n",
        "Random_tensor=tr.rand(3,4);\n",
        "print(Random_tensor)\n",
        "##Create a random tensor with similar shape to an image tensor;\n",
        "random_image_tensor=tr.rand(size=(3,224,224))##h,w and color channels(rgb)\n",
        "random_image_tensor.shape,random_image_tensor.ndim\n",
        "\n",
        "####################Creating tensor with Zeros#############################\n",
        "zeros=tr.zeros(size=(3,4))\n",
        "zeros\n",
        "mzt=zeros*Random_tensor\n",
        "mzt\n",
        "##Create a range of tensor\n",
        "##use torch.range\n",
        "t_range=tr.range(0,10);\n",
        "print(sum(t_range))\n",
        "one_to_ten=tr.arange(start=1,end=100,step=1)\n",
        "one_to_ten\n",
        "\n",
        "##Creating tensor like\n",
        "one_to_ten=tr.zeros_like(\n",
        "    input=one_to_ten\n",
        ")\n",
        "print(one_to_ten);\n",
        "\n",
        "tenzeros=tr.zeros_like(input=one_to_ten)\n",
        "tenzeros\n",
        "\n",
        "##Float 32 tensor\n",
        "float_32_tensor=tr.tensor(\n",
        "    [3.0,6.0,9.0],\n",
        "    dtype=None, ##what datatype is tensor\n",
        "    device=None,\n",
        "    requires_grad=False)\n",
        "float_32_tensor.dtype\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note: Tensor datatype is one of the 3 big errorrs you will run into  with Pytorch & deep learning\n",
        " 1.tensors not right datatype\n",
        " 2.tensors not right shape\n",
        " 3.tensors not on the right device\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "IbVM-Oy-3E6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Float 32 tensor\n",
        "float_32_tensor=tr.tensor(\n",
        "    [3.0,6.0,9.0],\n",
        "    dtype=None, ##what datatype is the tensor (float32 or float 16)\n",
        "    device=None,##What device is your tensor on\n",
        "    requires_grad=False)##Whether or not to track gradients with this tensor operation\n",
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBoEcy8N35Wk",
        "outputId": "91692def-e035-4ff9-98c5-39fea9fed264"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Float16 tensor\n",
        "float_16_tensor=float_32_tensor.type(tr.float16);\n",
        "float_16_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmOrpWvz4T5i",
        "outputId": "d78cebb3-1d67-49f7-b42f-9c2c46a0e4d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##float64 tensor\n",
        "float_64_tensor=float_32_tensor.type(tr.float64);\n",
        "float_64_tensor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPS0yVsI4uih",
        "outputId": "7a5b9671-feef-4365-dfa1-6bf6a5ddd1d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_multiplication=float_32_tensor*float_64_tensor*float_16_tensor;\n",
        "tr_multiplication\n",
        "\n",
        "int_32_tensor=tr.tensor(\n",
        "    [3,6,9],\n",
        "    dtype=tr.int32\n",
        "    )\n",
        "int_32_tensor\n",
        "\n",
        "int_32_tensor=tr.tensor([3,6,9],dtype=tr.long)\n",
        "print(int_32_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qmq53Paa5IC0",
        "outputId": "aa173667-66e1-4134-e571-615d3f248608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 6, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Getting information for tensor\n",
        "1.tensor not right datatype-to do get datatypes from a tensor,can use `tensor.dtype`\n",
        "2.tensor not right shape -to get shape from a tensor,can use `tensor.shape`\n",
        "3.tensor not on the right device-to get device from a tensor , can use `tensor.device`\n"
      ],
      "metadata": {
        "id": "v-g8xtRx6RTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "some_tensor=tr.rand(3,4)\n",
        "print(some_tensor);\n",
        "print(f\"shape of the tensor:{some_tensor.dtype}\")\n",
        "print(f\"shape of the tensor:{some_tensor.shape}\")\n",
        "print(f\"shape of the tensor:{some_tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5UOzK5Y7Qm_",
        "outputId": "940f9f00-5819-42b7-a81e-180aa85a7038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0851, 0.7136, 0.2096, 0.2978],\n",
            "        [0.1866, 0.1656, 0.6805, 0.5712],\n",
            "        [0.2701, 0.9697, 0.4068, 0.7093]])\n",
            "shape of the tensor:torch.float32\n",
            "shape of the tensor:torch.Size([3, 4])\n",
            "shape of the tensor:cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Manipulating tensors (tensors operation)\n",
        "*Addition\n",
        "*Subtraction\n",
        "*Multiplication\n",
        "*Division\n",
        "*Matrix multiplication\n",
        "\n"
      ],
      "metadata": {
        "id": "lJB9cxML81bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Manupulating tensor\n",
        "##Create a tensor\n",
        "tensor=tr.tensor([1,2,3])\n",
        "tensor+=10;##Addintion\n",
        "tensor\n",
        "##Multiply tensor by 10\n",
        "tensor*=10;##Multiplication\n",
        "tensor\n",
        "\n",
        "tensor//=10;##Division\n",
        "tensor\n",
        "\n",
        "tensor-=10;##subtraction\n",
        "tensor\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLFuNM0Z8jTc",
        "outputId": "e76a964d-54f8-4715-d283-b8bb5d194fbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Matrix multiplication\n",
        "=>Elements-wise multiplication\n",
        "\n",
        "=>matrix Multiplication(dot product multiplication)\n",
        "\n",
        "=>elements wise multiplication\n",
        "\n",
        "More information on multiplication-matrix:https://www.mathsisfun.com/algebramatrix-introduction.html\n",
        "\n",
        "or,\n",
        "\n",
        "http://matrixmultiplication.xyz/\n",
        "\n",
        "There are 2 main rules that performing matrix multiplication need s to sattisfy :\n",
        "\n",
        "The **inner dimension ** must match:\n",
        "\n",
        "*`(3,2) @ (3,2)` will not work\n",
        "\n",
        "*`(2,3)@ (3,2)` will work\n",
        "\n",
        "*`(3,2) @ (2,3)`  will work\n",
        "\n",
        "2.The resulting matrix has the shape of the  **outer dimensions**\n",
        "\n",
        "*`(2,3) @ (3,2) -> (2,2)`\n",
        "\n",
        "*`(3,2) @(2,3) ->(3,3)`\n"
      ],
      "metadata": {
        "id": "cCoR1NFbJykb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor,\"*\",tensor)\n",
        "print(f\"Equals:{tensor*tensor}\")\n",
        "##Matrix multiplication\n",
        "print(tr.matmul(tensor,tensor))\n",
        "\n",
        "%%time\n",
        "value=0;\n",
        "for i in range(len(tensor)):\n",
        "  value=value+tensor[i]*tensor[i];\n",
        "print(value)\n",
        "%%time\n",
        "tr.matmul(tensor,tensor)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXWR6afIK-ZA",
        "outputId": "37bc9570-1f62-4a29-a780-de669a1836b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals:tensor([1, 4, 9])\n",
            "tensor(14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: Line magic function `%%time` not found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tr.matmul(tr.rand(10,10),tr.rand(10,10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewJ406igOS7j",
        "outputId": "a97edfa4-48bc-4273-d437-b3b828b8c9e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.3677, 2.5948, 2.2612, 2.6349, 2.2059, 2.2775, 2.2081, 1.6204, 1.1784,\n",
              "         1.7134],\n",
              "        [2.3824, 1.9577, 1.8402, 1.4529, 2.0575, 1.8464, 1.3945, 1.6060, 1.2578,\n",
              "         1.9509],\n",
              "        [1.8975, 2.4054, 2.1703, 3.0683, 2.2657, 2.1912, 3.0544, 2.0818, 1.4970,\n",
              "         2.0634],\n",
              "        [2.4503, 2.2058, 2.2660, 3.0692, 2.2984, 2.1805, 2.8249, 2.5359, 2.1560,\n",
              "         3.0172],\n",
              "        [2.7331, 2.4974, 2.4092, 1.9792, 2.7683, 1.8139, 2.3400, 2.2061, 1.4063,\n",
              "         2.2219],\n",
              "        [1.6095, 1.7767, 1.7062, 2.2618, 1.7069, 1.5929, 2.1102, 1.5658, 1.3949,\n",
              "         1.9314],\n",
              "        [2.9735, 2.7061, 2.4045, 2.4835, 2.9232, 2.1574, 3.1210, 2.9085, 1.9758,\n",
              "         2.8045],\n",
              "        [2.2255, 1.9913, 2.3226, 2.2400, 2.4331, 1.7749, 2.0216, 1.9397, 1.6168,\n",
              "         2.5986],\n",
              "        [2.6004, 2.0451, 2.1411, 1.6741, 2.4140, 1.9709, 1.5402, 1.9391, 1.5193,\n",
              "         2.5139],\n",
              "        [2.8349, 2.7125, 2.1764, 2.0745, 2.5145, 1.9913, 2.6616, 2.2742, 1.7484,\n",
              "         2.2642]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##One of the most common errors in deep Learning shape errors\n",
        "\n",
        "http://matrixmultiplication.xyz/"
      ],
      "metadata": {
        "id": "XpCIPIS5PwTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor_A=tr.tensor([\n",
        "#     [1,2],\n",
        "#     [3,4],\n",
        "#     [5,6]\n",
        "# ])\n",
        "# tensor_B=tr.tensor([\n",
        "#     [7,10],\n",
        "#     [8,11],\n",
        "#     [9,12]\n",
        "# ])\n",
        "'''\n",
        "  ---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "/tmp/ipython-input-73-4129593472.py in <cell line: 0>()\n",
        "      9     [9,12]\n",
        "     10 ])\n",
        "---> 11 if (tr.matmul(tensor_A,tensor_B)==False):\n",
        "     12   print(\"mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\")\n",
        "\n",
        "RuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n",
        "\n",
        "  '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "T3NOi9wAQXpI",
        "outputId": "7f11d99c-b4b6-4e4e-a110-acadfff6cc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  ---------------------------------------------------------------------------\\nRuntimeError                              Traceback (most recent call last)\\n/tmp/ipython-input-73-4129593472.py in <cell line: 0>()\\n      9     [9,12]\\n     10 ])\\n---> 11 if (tr.matmul(tensor_A,tensor_B)==False):\\n     12   print(\"mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\")\\n\\nRuntimeError: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\\n\\n  '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To fix our tensor shape issues ,we can multiplle the shape of one of our tensors using  a **tranpose**\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor"
      ],
      "metadata": {
        "id": "wR6Rsk4xRj5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor_B.T)##Transpose matrix\n",
        "print()\n",
        "print(tensor_B)##Normal   matrix\n",
        "print(\"tensor_A shape\",tensor_A.shape,\"\\n\")\n",
        "print(\"tensor_A(Transpose matrix)\",tensor_A.T,\"\\n\");\n",
        "print(\"tensor_A Transpose-shape\",tensor_A.T.shape,\"\\n\")\n",
        "print(\"shape-tensorB\",tensor_B.shape,\"\\n\")##shape of the tensor\n",
        "print(\"Transpose matrix-shape\",tensor_B.T.shape,\"\\n\")##Transpose matrix shape\n",
        "output_tensor=tr.matmul(tensor_A,tensor_B.T)\n",
        "print(\"Output of the mulication shape\",output_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNDv4nbJSC4-",
        "outputId": "3e646bf2-dda3-4a0a-c7b4-0fe0cad91422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 7,  8,  9],\n",
            "        [10, 11, 12]])\n",
            "\n",
            "tensor([[ 7, 10],\n",
            "        [ 8, 11],\n",
            "        [ 9, 12]])\n",
            "tensor_A shape torch.Size([3, 2]) \n",
            "\n",
            "tensor_A(Transpose matrix) tensor([[1, 3, 5],\n",
            "        [2, 4, 6]]) \n",
            "\n",
            "tensor_A Transpose-shape torch.Size([2, 3]) \n",
            "\n",
            "shape-tensorB torch.Size([3, 2]) \n",
            "\n",
            "Transpose matrix-shape torch.Size([2, 3]) \n",
            "\n",
            "Output of the mulication shape tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Finding the min,max,mean,sum,etc(tensor aggregation)\n",
        "x=tr.arange(0,100,10)\n",
        "x\n",
        "#Find the min\n",
        "print(tr.min(x),x.min())\n",
        "print(tr.max(x),x.max())\n",
        "##Find the mean-note the torch.mean() function requires a tensor of float32 datatype to work\n",
        "print(tr.mean(x.type(tr.float32)))\n",
        "print(tr.mean(x.type(tr.float64)))\n",
        "\n",
        "##Find the sum\n",
        "s=tr.sum(x),x.sum()\n",
        "print(s)\n",
        "\n",
        "'''\n",
        "Finding the positiona; min and max of the tensors that has the minimum value with argmin->\n",
        "return index position of target tensor where the minimum value occurs\n",
        "'''\n",
        "print(\"argmin=>\",x.argmin())\n",
        "\n",
        "##Find the position in tensor that has the minimum with argmax\n",
        "print(x[9])\n",
        "print(\"argmax\",x.argmax())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoQS-TZ9VDqU",
        "outputId": "7749c5f7-f78e-47ce-825d-82c5dd4083af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0) tensor(0)\n",
            "tensor(90) tensor(90)\n",
            "tensor(45.)\n",
            "tensor(45., dtype=torch.float64)\n",
            "(tensor(450), tensor(450))\n",
            "argmin=> tensor(0)\n",
            "tensor(90)\n",
            "argmax tensor(9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reshaping,staking,squeezing and Unsqueezing in tensor\n",
        "\n",
        "*Reshaping-reshape an input tensor to a defined shape\n",
        "\n",
        "*view- Return a view of an input tensor of certain shape but keep the same memory\n",
        "as the original  tensor\n",
        "\n",
        "*staking-combine multiple tensors on top of each other(vstack) or side by side (hstack)\n",
        "\n",
        "*squeezing-removes all `1` dimensions from a tensor\n",
        "\n",
        "*unsqueezing-add a `1` dimension to a target tensor\n",
        "\n",
        "*Permute-return a view of the input with diemnsions permuted(swapped) in a certain way"
      ],
      "metadata": {
        "id": "GFMQhCK-seS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Reshaping\n",
        "x=tr.arange(1.,10.)\n",
        "x_reshape=x.reshape(1,9)\n",
        "'''\n",
        "output:\n",
        "tensor([[1.],\n",
        "        [2.],\n",
        "        [3.],\n",
        "        [4.],\n",
        "        [5.],\n",
        "        [6.],\n",
        "        [7.],\n",
        "        [8.],\n",
        "        [9.]])\n",
        "\n",
        "\n",
        "'''\n",
        "##=====================================================================\n",
        "'''\n",
        "x_reshape=x.reshape(1,7)\n",
        "---------------------------------------------------------------------------\n",
        "RuntimeError                              Traceback (most recent call last)\n",
        "/tmp/ipython-input-114-605409409.py in <cell line: 0>()\n",
        "      1 ##Reshaping\n",
        "      2 x=tr.arange(1.,10.)\n",
        "----> 3 x_reshape=x.reshape(1,7)\n",
        "      4 x_reshape\n",
        "      5 ##Stacking\n",
        "\n",
        "RuntimeError: shape '[1, 7]' is invalid for input of size 9\n",
        "'''\n",
        "x_reshape=x.reshape(9,1)\n",
        "x_reshape=x.reshape(1,9)\n",
        "x_reshape=x.reshape(3,3)\n",
        "x_reshape\n",
        "##view\n",
        "z=x.view(1,9)\n",
        "z\n",
        "#Changing z changes x(because a view of a tensor shares the same memory as  the original input)\n",
        "z[:,0]\n",
        "z,x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgbIWUJPr4gf",
        "outputId": "dc15fc39-ec50-4754-cfe7-006ccaa88f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Stacking tensor on of the other\n",
        "x_stacked=tr.stack([x,x,x,x],dim=0)\n",
        "print(x_stacked)\n",
        "print(\"=====================================================\",\"\\n\")\n",
        "x_stacked=tr.stack([x,x,x,x],dim=1)\n",
        "print(x_stacked)\n",
        "x_stacked\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kubUjxLtumql",
        "outputId": "9a1d9300-8c8e-44b7-dae9-279e2706e39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
            "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "===================================================== \n",
            "\n",
            "tensor([[1., 1., 1., 1.],\n",
            "        [2., 2., 2., 2.],\n",
            "        [3., 3., 3., 3.],\n",
            "        [4., 4., 4., 4.],\n",
            "        [5., 5., 5., 5.],\n",
            "        [6., 6., 6., 6.],\n",
            "        [7., 7., 7., 7.],\n",
            "        [8., 8., 8., 8.],\n",
            "        [9., 9., 9., 9.]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Squeezing tensor-remove all single dimension from a target tensor\n",
        "\n",
        "\n",
        "# Assuming x_reshape is your input tensor with single dimensions\n",
        "# Example tensor with single dimensions\n",
        "x_reshape = tr.randn(1, 3, 1, 2)  # Shape: [1, 3, 1, 2]\n",
        "print(f\"Previous tensor:\\n{x_reshape}\")\n",
        "print(f\"Previous shape: {x_reshape.shape}\")\n",
        "\n",
        "# Remove all single dimensions\n",
        "squeezed_tensor = x_reshape.squeeze()\n",
        "print(\"\\nNew tensor after squeeze:\\n\", squeezed_tensor)\n",
        "print(\"Squeezed tensor shape:\", squeezed_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3IgwVkgwld-",
        "outputId": "1dd01d9e-9d85-468b-df3f-7bfee3da4904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor:\n",
            "tensor([[[[-0.6423, -0.8047]],\n",
            "\n",
            "         [[-1.9020,  0.2089]],\n",
            "\n",
            "         [[ 0.3818, -1.0484]]]])\n",
            "Previous shape: torch.Size([1, 3, 1, 2])\n",
            "\n",
            "New tensor after squeeze:\n",
            " tensor([[-0.6423, -0.8047],\n",
            "        [-1.9020,  0.2089],\n",
            "        [ 0.3818, -1.0484]])\n",
            "Squeezed tensor shape: torch.Size([3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##unsqueezing tensor-add a  single dimension  to a target tensor at a specific dim(dimension)\n",
        "\n",
        "print(\"Previous\",x_reshape);\n",
        "print(\"Previous Squezze-shape\",x_reshape.shape)\n",
        "\n",
        "##---------------------------------------\n",
        "x_unsquzzed=x_reshape.unsqueeze(dim=1);\n",
        "print(\"after x_unsquzzed\",x_unsquzzed)\n",
        "print(\"after x_unsquzzed_shape\",x_unsquzzed.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ-i6mcAwnU6",
        "outputId": "71e26258-539d-4c89-f0a1-1a4901fe941e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor([[[[-0.6423, -0.8047]],\n",
            "\n",
            "         [[-1.9020,  0.2089]],\n",
            "\n",
            "         [[ 0.3818, -1.0484]]]])\n",
            "Previous Squezze-shape torch.Size([1, 3, 1, 2])\n",
            "after x_unsquzzed tensor([[[[[-0.6423, -0.8047]],\n",
            "\n",
            "          [[-1.9020,  0.2089]],\n",
            "\n",
            "          [[ 0.3818, -1.0484]]]]])\n",
            "after x_unsquzzed_shape torch.Size([1, 1, 3, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##torch.permute\n",
        "a=224#height,\n",
        "b=224#width\n",
        "c=3## colour-channels\n",
        "\n",
        "x_original=tr.rand(a,b,c)\n",
        "print(\"size of x is\",x_original,\"\\n\")\n",
        "size_of_x=x_original.size();\n",
        "print(f\"size-of-x\",size_of_x)\n",
        "x_permuted=x_original.permute(2,0,1)##shifts axis 0->,1->2,2->0\n",
        "print(f\"permuted-shape:{x_permuted.shape},\\n\")##[colour_channel,height,width]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtpppB531l5i",
        "outputId": "341dae32-b380-4c0f-92b0-5f38c24c3d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "size of x is tensor([[[0.1551, 0.8985, 0.2874],\n",
            "         [0.2375, 0.2817, 0.9394],\n",
            "         [0.7947, 0.7344, 0.1228],\n",
            "         ...,\n",
            "         [0.9210, 0.6324, 0.5919],\n",
            "         [0.8547, 0.2507, 0.5319],\n",
            "         [0.6237, 0.5974, 0.0907]],\n",
            "\n",
            "        [[0.8835, 0.1620, 0.2947],\n",
            "         [0.7828, 0.3073, 0.7552],\n",
            "         [0.7251, 0.0308, 0.7358],\n",
            "         ...,\n",
            "         [0.3070, 0.9451, 0.5594],\n",
            "         [0.6064, 0.8501, 0.1541],\n",
            "         [0.3538, 0.5579, 0.9674]],\n",
            "\n",
            "        [[0.5739, 0.1521, 0.1678],\n",
            "         [0.0386, 0.1459, 0.0163],\n",
            "         [0.3493, 0.6782, 0.5040],\n",
            "         ...,\n",
            "         [0.2333, 0.1481, 0.5022],\n",
            "         [0.9682, 0.6657, 0.5688],\n",
            "         [0.3933, 0.6261, 0.0898]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.2550, 0.1246, 0.9707],\n",
            "         [0.7634, 0.6494, 0.2226],\n",
            "         [0.5746, 0.8648, 0.2036],\n",
            "         ...,\n",
            "         [0.9881, 0.8097, 0.3481],\n",
            "         [0.9081, 0.0154, 0.5227],\n",
            "         [0.6866, 0.4373, 0.8209]],\n",
            "\n",
            "        [[0.2383, 0.4900, 0.9267],\n",
            "         [0.1051, 0.8902, 0.4239],\n",
            "         [0.9295, 0.9970, 0.4563],\n",
            "         ...,\n",
            "         [0.2653, 0.7624, 0.7221],\n",
            "         [0.7143, 0.0874, 0.6761],\n",
            "         [0.3798, 0.7486, 0.4950]],\n",
            "\n",
            "        [[0.6762, 0.8342, 0.6634],\n",
            "         [0.3050, 0.3278, 0.3087],\n",
            "         [0.0257, 0.6221, 0.6645],\n",
            "         ...,\n",
            "         [0.2469, 0.1732, 0.8431],\n",
            "         [0.0528, 0.3869, 0.6020],\n",
            "         [0.9583, 0.7204, 0.0808]]]) \n",
            "\n",
            "size-of-x torch.Size([224, 224, 3])\n",
            "permuted-shape:torch.Size([3, 224, 224]),\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0,0,0]=728218\n",
        "x_original[0,0,0],x_permuted[0,0,0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3klJHTDk3hVO",
        "outputId": "ec112488-b3f5-423b-aed4-02fc6f5eac0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(728218.), tensor(728218.))"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with Pytorch is similar to indexing with Numpy.\n",
        "\n"
      ],
      "metadata": {
        "id": "CKfhsDBr3wK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Create a tensor\n",
        "x=tr.arange(1,10).reshape(1,3,3)\n",
        "c=print;\n",
        "c(x)\n",
        "c(x,x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeJ9cl6G3_JW",
        "outputId": "0a4bd811-c649-406e-a4a3-81e6da7be579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]]) torch.Size([1, 3, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Lets Index on our new tensor\n",
        "c(\"Index on our new tensor\",x[0])\n",
        "##Lets index on the middle bracket\n",
        "c(\"Index on our middle bracket\",x[0][0])\n",
        "##Lets index on the most inner bracket (last dimension)\n",
        "c(\"Index on our most inner bracket\",x[0][0][0])\n",
        "c(\"Index on our most inner bracket\",x[0][0][1])\n",
        "c(\"Index on our most inner bracket\",x[0][0][2])\n",
        "c(\"Index on our most inner bracket\",x[0][1][1])\n",
        "##We can also use : to select \"all\" of a target dimension\n",
        "c(x[:,0])\n",
        "c([[1,2,3]])\n",
        "##Get all values of the 0th and last dimensions but only index 1 of 2nd dimensions\n",
        "c(x[:,:,1]);\n",
        "\n",
        "##Get all values of the 0 dimensions but only the 1 index value of the 1st and 2nd dimension\n",
        "c(x[:,1,1])\n",
        "\n",
        "##Get index 0 of 0th 1st dimension and all values of 2nd dimension\n",
        "c(x[0,0,:])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyNdBI_34pzu",
        "outputId": "078ce25e-0535-43c8-a252-e089bd233eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index on our new tensor tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Index on our middle bracket tensor([1, 2, 3])\n",
            "Index on our most inner bracket tensor(1)\n",
            "Index on our most inner bracket tensor(2)\n",
            "Index on our most inner bracket tensor(3)\n",
            "Index on our most inner bracket tensor(5)\n",
            "tensor([[1, 2, 3]])\n",
            "[[1, 2, 3]]\n",
            "tensor([[2, 5, 8]])\n",
            "tensor([5])\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Index on x to return 9\n",
        "c(x)\n",
        "c(x[:,:,2])\n",
        "## Index on x to return 3,6,9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDkh2rgt7VDu",
        "outputId": "0d3fdd05-31bc-44e7-9d0d-6073d8d11bc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1, 2, 3],\n",
            "         [4, 5, 6],\n",
            "         [7, 8, 9]]])\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Pytorch tensor & Numpy\n",
        "Numpy is a popular scientific Python numerical computing library\n",
        "And because of this Pytorch has functionality to interact with it\n",
        "\n",
        "*Data in Numpy, want in Pytorch tensor\n",
        "-> `torch.from_numpy(ndarray)`\n",
        "\n",
        "\n",
        "*Pytorch tensor-> Numpy-> `torch.Tensor.numpy()`\n",
        "\n"
      ],
      "metadata": {
        "id": "b8titPRl8aPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch tensor & Numpy\n",
        "'''Data in Numpy, want in Pytorch tensor-> `torch.from_numpy(ndarray)`'''\n",
        "array=np.arange(1.0,8.0)\n",
        "tensor=tr.from_numpy(array)\n",
        "print(f\"from_numpy-array:{array}\")\n",
        "c(\"Type of array is\",array.dtype)\n",
        "c(\"Type of tensor is\",tensor.dtype)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ax77O74N8HYj",
        "outputId": "f9718dea-e1fd-46a1-82a3-9342d5c6c39e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "from_numpy-array:[1. 2. 3. 4. 5. 6. 7.]\n",
            "Type of array is float64\n",
            "Type of tensor is torch.float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Change the value of array,what will this do to `tensor`\n",
        "array=array+1\n",
        "c(\"array:\",array)\n",
        "c(\"tensor:\",tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35aw2ws5AFJR",
        "outputId": "58faab60-31e0-4c8b-f7fb-ac1a8981744a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "array: [2. 3. 4. 5. 6. 7. 8.]\n",
            "tensor: tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Tensor  to Numpy array\n",
        "'''*Pytorch tensor-> Numpy-> `torch.Tensor.numpy()`''\n",
        "tensor=tr.ones(7);\n",
        "c(\"tensor: \",tensor)\n",
        "c(\"Numpy-tensor\",tensor.numpy())##Numpy tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-3iqKbwAdCb",
        "outputId": "28bb8fc2-bfd1-4616-9e7b-ce0707d46f54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor:  tensor([1., 1., 1., 1., 1., 1., 1.])\n",
            "Numpy tensor [1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Change the tensor,what happens to `numpy_tensor`\n",
        "tensor=tensor+1;\n",
        "c(\"Tensor\",tensor)\n",
        "c(\"Numpy_tensor\",tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2kR-meA81A",
        "outputId": "b834336e-c901-4d34-bb3f-776133c3d66b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor tensor([2., 2., 2., 2., 2., 2., 2.])\n",
            "Numpy_tensor [2. 2. 2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preproducbility (Trying to take random out of random)\n",
        "In short how a neural network learns:\n",
        "\n",
        "`Start with random numbers->tensor operations->update random numbers to try and make them better represtations of the data -> again ->again->again->again...`\n",
        "\n",
        "To reduce the randomess in neural networks and Pytorch comes the concepts of a **random seed**\n",
        "\n",
        "Essentially what the random seed does is \"flavour\" the randomness\n",
        "\n",
        "##For more information:\n",
        "https://docs.pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "https://en.wikipedia.org/wiki/Pseudorandom_number_generator\n",
        "\n"
      ],
      "metadata": {
        "id": "8A7blFFdBrRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Create 2 randoms tensors\n",
        "randoms_tensor_A=tr.rand(3,4)\n",
        "random_tensor_B=tr.rand(3,4);\n",
        "print(f\"random_tensor_A:{randoms_tensor_A}\")\n",
        "print(f\"random_tensor_B:{random_tensor_B}\");\n",
        "c(randoms_tensor_A==random_tensor_B)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTOI3R4i9fX6",
        "outputId": "f055388c-0d47-441a-acac-b5671d3c6082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "random_tensor_A:tensor([[0.3480, 0.0145, 0.3927, 0.2965],\n",
            "        [0.7285, 0.0231, 0.3785, 0.8212],\n",
            "        [0.3786, 0.9325, 0.5510, 0.1374]])\n",
            "random_tensor_B:tensor([[0.0820, 0.4387, 0.2393, 0.0272],\n",
            "        [0.8831, 0.0851, 0.7210, 0.4000],\n",
            "        [0.6023, 0.3649, 0.6435, 0.3914]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Lets make some rendom but reproducible tensors\n",
        "##Set the random seed\n",
        "RANDOM_SEED=42\n",
        "c=print\n",
        "c(\"before-manual-seed\",tr.manual_seed(RANDOM_SEED))\n",
        "random_tensor_C=tr.rand(3,4);\n",
        "c(\"after-manual-seed\",tr.manual_seed(RANDOM_SEED))\n",
        "randoms_tensor_D=tr.rand(3,4);\n",
        "c(\"random_tensor_C:\\n\",random_tensor_C)\n",
        "c(\"random_tensor_D:\\n\",randoms_tensor_D)\n",
        "c(random_tensor_C==randoms_tensor_D)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ic93pyEPnC",
        "outputId": "00a0ec77-4d6a-470d-bf68-be90b582897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before-manual-seed <torch._C.Generator object at 0x7f3c883c1450>\n",
            "after-manual-seed <torch._C.Generator object at 0x7f3c883c1450>\n",
            "random_tensor_C:\n",
            " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "random_tensor_D:\n",
            " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Running tensors and Pytorch objects on the GPUs(and making faster computations)\n",
        "\n",
        "Different ways of accessing a gpu in pytorch\n",
        "\n",
        "GPUs=faster computation on numbers,thanks to CUDA+NVIDIA  hardware +Pytorch working behind the scenes to make everything  hunky dory (good)\n",
        "\n",
        "1.Easiest-Use Google Colab for a free GPU (option to upgrade as well)\n",
        "\n",
        "2.Use your own GPU-takes a little bit of setup and requires the invesment of purchasing GPU ,there is a lots of options...see this blog: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/\n",
        "\n",
        "3.Use cloud computing-GCP,AWS,Azure,these serveices allows you to rent computers on the cloud and access  them\n",
        "\n",
        "for 2,3 Pytorch+GPU drivers(CUDA) takes a little bit of settings up,to do this,refer to Pytorch setup documentation:https://pytorch.org/get-started/locally/\n",
        "\n",
        "CUDA semantics:\n",
        "https://docs.pytorch.org/docs/stable/notes/cuda.html"
      ],
      "metadata": {
        "id": "-uLj4HIhHxMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Running tensors and Pytorch objects on the GPUs(and making faster computations)\n",
        "##Different ways of accessing a gpu in pytorch\n",
        "##Check for GPU access with Python\n",
        "import torch as tr\n",
        "tr.cuda.is_available()\n",
        "device=\"cuda\"\n",
        "if tr.cuda.is_available():\n",
        "  device=\"cuda\"\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "print(\"device Is\",device)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSYMhdRJGcVG",
        "outputId": "5f2cfd81-ad0f-447d-879c-ea946cc18a43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device Is cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Pytorch since its capaable of running computer on the GPU or CPU its best practice to setup device agnostic code:https://docs.pytorch.org/docs/stable/notes/cuda.html\n",
        "\n",
        "\n",
        "E.g run on GPU if available ,else default to CPU"
      ],
      "metadata": {
        "id": "5HXvTOojNDrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setting up device agnostic code and putting tensors on and off GPU\n",
        "\n",
        "##Putting tensors (and models) on the GPU\n",
        "\n",
        "The reson we want our tensors/models on the GPU is bacause using a GPU in faster computaion"
      ],
      "metadata": {
        "id": "E4K1FKw4eE3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Setting up device agnostic code and putting tensors on and off GPU\n",
        "##Putting tensors (and models) on the GPU\n",
        "import torch as tr;\n",
        "c=print\n",
        "tensor=tr.tensor([1,2,3],device=\"cpu\")\n",
        "c(tensor)\n"
      ],
      "metadata": {
        "id": "eMEVH7JENpTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7178b40e-a8bc-4779-fe23-b33d1dd64a3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Move tensor to GPU(if avaibale)\n",
        "tr.cuda.is_available()\n",
        "device=\"cuda\"\n",
        "if tr.cuda.is_available():\n",
        "  device=\"cuda/gpu\"\n",
        "else:\n",
        "  device=\"cpu\"\n",
        "print(\"device Is\",device)\n",
        "tensor_on_gpu=tensor.to(device)\n",
        "c(tensor_on_gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMiutnBue38E",
        "outputId": "246304d6-000c-4493-f7e5-c8c78af0f454"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device Is cpu\n",
            "tensor([1, 2, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Moving tensor to CPU\n",
        "#if tensor is GPU,canot tranform it Numpy;\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUIPwKJDfZ0x",
        "outputId": "8bb6d529-de5c-4826-a260-1e636dc3118e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#To fix the GPU tensor with Numpy issue,we can first set it to the CPU\n",
        "tensor_back_on_cpu=tensor_on_gpu.cpu().numpy();\n",
        "c(tensor_back_on_cpu)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vNqu1YLf1GR",
        "outputId": "a075bef3-b448-4472-eda6-a324d6409b03"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Excercises & Extra-curriculum\n",
        "\n",
        "Sea excercises for this notebook here:\n",
        "https://www.learnpytorch.io/00_pytorch_fundamentals/#exercises\n",
        "\n",
        "Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on [torch.Tensor]:https://docs.pytorch.org/docs/stable/tensors.html#torch-tensor and for [torch.cuda]:https://docs.pytorch.org/docs/main/notes/cuda.html#cuda-semantics\n",
        "\n",
        "For excercise and Solution:https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb"
      ],
      "metadata": {
        "id": "GCMMtGZWhJ8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Excercises\n",
        "c(tr.tensor([7,7]))\n",
        "c(tr.rand(7,7))\n",
        "##Escercise:Please click for excercise\n",
        "##https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-N103wag1Bm",
        "outputId": "dac4485b-ac6c-4f48-ad50-fee4f47664c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([7, 7])\n",
            "tensor([[0.2873, 0.3309, 0.9663, 0.0567, 0.7353, 0.9473, 0.9455],\n",
            "        [0.1574, 0.0943, 0.5450, 0.1226, 0.8932, 0.3140, 0.2119],\n",
            "        [0.0036, 0.5335, 0.8561, 0.6143, 0.5356, 0.5445, 0.5170],\n",
            "        [0.8515, 0.3478, 0.3092, 0.0429, 0.9818, 0.1101, 0.7755],\n",
            "        [0.3991, 0.2566, 0.6844, 0.7641, 0.0086, 0.5942, 0.8248],\n",
            "        [0.0033, 0.8902, 0.6461, 0.6744, 0.8321, 0.1038, 0.0424],\n",
            "        [0.1175, 0.9427, 0.7770, 0.9941, 0.5198, 0.4150, 0.8743]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pytorch workflow\n",
        "Lets explore an example pytorch end-to-end workflow\n",
        "Please visiit the link:https://github.com/mrdbourke/pytorch-deep-learning/blob/main/01_pytorch_workflow.ipynb\n",
        "\n",
        "Book Version of notebook:https://www.learnpytorch.io/01_pytorch_workflow/\n",
        "\n"
      ],
      "metadata": {
        "id": "ILhK36jWnC10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "what_were_covering={\n",
        "    1:\"data(prepare and load)\",\n",
        "    2:\"build model\",\n",
        "    3:\"fitting the model to data(training)\",\n",
        "    4:\"making predictions and evaluating a model(inference)\",\n",
        "    5:\"saving and loading a model\",\n",
        "    6:\"putting it all together\"\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "id": "FtTR1kM_oLkM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparaing and Loading\n",
        "\n",
        "data can be almost anything ...in machine Learning\n",
        "\n",
        "*Excel spreadshet\n",
        "\n",
        "*Image of any kind\n",
        "\n",
        "*Videos(Youtube has lots of data)\n",
        "\n",
        "*Audio like songs or pocast\n",
        "\n",
        "*DNA\n",
        "\n",
        "*Text\n",
        "\n",
        "Machine learning is a game of 2 Parts\n",
        "\n",
        "1.Get data into a numerical Represtation\n",
        "\n",
        "2.Build a model to learn patterns in that numerical representaion(https://www.ncl.ac.uk/webtemplate/ask-assets/external/maths-resources/statistics/regression-and-correlation/simple-linear-regression.html#:~:text=The%20simple%20linear%20regression%20line%2C%20%5Ey%3Da%2Bb,every%20unit%20change%20in%20x%20.)\n",
        "\n",
        "\n",
        "\n",
        "To showcase this,lets create some **known** data using the linear regression formula.\n",
        "\n",
        "We will use a linear regression formula to make a straight line with known **parameter**\n",
        "\n"
      ],
      "metadata": {
        "id": "3Ca6qC2nqJGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create \"known\" parameters\n",
        "weight=0.7\n",
        "bias=0.3\n",
        "#create\n",
        "start=0;\n",
        "end=1;\n",
        "step=0.02\n",
        "x=tr.arange(start,end,step).unsqueeze(dim=1)\n",
        "y=weight*x+bias;\n",
        "c(\"x[:10]=>\",x[:10])\n",
        "c(\"y[:10]=>\",y[:10])\n",
        "c(\"length :\",len(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF2wgFIZwQ42",
        "outputId": "1d76c0a3-553b-4066-916d-771682c15446"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x[:10]=> tensor([[0.0000],\n",
            "        [0.0200],\n",
            "        [0.0400],\n",
            "        [0.0600],\n",
            "        [0.0800],\n",
            "        [0.1000],\n",
            "        [0.1200],\n",
            "        [0.1400],\n",
            "        [0.1600],\n",
            "        [0.1800]])\n",
            "y[:10]=> tensor([[0.3000],\n",
            "        [0.3140],\n",
            "        [0.3280],\n",
            "        [0.3420],\n",
            "        [0.3560],\n",
            "        [0.3700],\n",
            "        [0.3840],\n",
            "        [0.3980],\n",
            "        [0.4120],\n",
            "        [0.4260]])\n",
            "length : 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Spliting data into training and test sets(one of the most important concepts in machine learning)\n",
        "\n",
        "Lets create a training and test set with our data"
      ],
      "metadata": {
        "id": "S44B5Khjy_1R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Create a train/test split\n",
        "train_split=(0.8*len(x))\n",
        "train_split=int(train_split)\n",
        "x_train,y_train=x[:train_split],y[:train_split]\n",
        "x_test,y_test=x[train_split:],y[train_split:]\n",
        "print(f\"x-train:{x_train}\")\n",
        "print(f\"y-train:{y_train}\")\n",
        "print(f\"x-test:{x_test}\")\n",
        "print(f\"y_test:{y_test}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJtRKZ9FzLp5",
        "outputId": "e3f67ed5-5385-4d1f-bb32-ce950df5da71"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x-train:tensor([[0.0000],\n",
            "        [0.0200],\n",
            "        [0.0400],\n",
            "        [0.0600],\n",
            "        [0.0800],\n",
            "        [0.1000],\n",
            "        [0.1200],\n",
            "        [0.1400],\n",
            "        [0.1600],\n",
            "        [0.1800],\n",
            "        [0.2000],\n",
            "        [0.2200],\n",
            "        [0.2400],\n",
            "        [0.2600],\n",
            "        [0.2800],\n",
            "        [0.3000],\n",
            "        [0.3200],\n",
            "        [0.3400],\n",
            "        [0.3600],\n",
            "        [0.3800],\n",
            "        [0.4000],\n",
            "        [0.4200],\n",
            "        [0.4400],\n",
            "        [0.4600],\n",
            "        [0.4800],\n",
            "        [0.5000],\n",
            "        [0.5200],\n",
            "        [0.5400],\n",
            "        [0.5600],\n",
            "        [0.5800],\n",
            "        [0.6000],\n",
            "        [0.6200],\n",
            "        [0.6400],\n",
            "        [0.6600],\n",
            "        [0.6800],\n",
            "        [0.7000],\n",
            "        [0.7200],\n",
            "        [0.7400],\n",
            "        [0.7600],\n",
            "        [0.7800]])\n",
            "y-train:tensor([[0.3000],\n",
            "        [0.3140],\n",
            "        [0.3280],\n",
            "        [0.3420],\n",
            "        [0.3560],\n",
            "        [0.3700],\n",
            "        [0.3840],\n",
            "        [0.3980],\n",
            "        [0.4120],\n",
            "        [0.4260],\n",
            "        [0.4400],\n",
            "        [0.4540],\n",
            "        [0.4680],\n",
            "        [0.4820],\n",
            "        [0.4960],\n",
            "        [0.5100],\n",
            "        [0.5240],\n",
            "        [0.5380],\n",
            "        [0.5520],\n",
            "        [0.5660],\n",
            "        [0.5800],\n",
            "        [0.5940],\n",
            "        [0.6080],\n",
            "        [0.6220],\n",
            "        [0.6360],\n",
            "        [0.6500],\n",
            "        [0.6640],\n",
            "        [0.6780],\n",
            "        [0.6920],\n",
            "        [0.7060],\n",
            "        [0.7200],\n",
            "        [0.7340],\n",
            "        [0.7480],\n",
            "        [0.7620],\n",
            "        [0.7760],\n",
            "        [0.7900],\n",
            "        [0.8040],\n",
            "        [0.8180],\n",
            "        [0.8320],\n",
            "        [0.8460]])\n",
            "x-test:tensor([[0.8000],\n",
            "        [0.8200],\n",
            "        [0.8400],\n",
            "        [0.8600],\n",
            "        [0.8800],\n",
            "        [0.9000],\n",
            "        [0.9200],\n",
            "        [0.9400],\n",
            "        [0.9600],\n",
            "        [0.9800]])\n",
            "y_test:tensor([[0.8600],\n",
            "        [0.8740],\n",
            "        [0.8880],\n",
            "        [0.9020],\n",
            "        [0.9160],\n",
            "        [0.9300],\n",
            "        [0.9440],\n",
            "        [0.9580],\n",
            "        [0.9720],\n",
            "        [0.9860]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How might we better visalize our data?\n",
        "\n",
        "\n",
        "This is where the data explorer's motto comes in\n",
        "\n",
        "\"Visualize,Visualize,Visualize\"\n",
        "\n"
      ],
      "metadata": {
        "id": "Hc-aIYd02FGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Build a function  to visualize the data\n",
        "import matplotlib.pyplot as plt;\n",
        "def plot_prediction(\n",
        "    train_data=x_train,\n",
        "    train_labels=y_train,\n",
        "    test_data=x_test,\n",
        "    test_labels=y_test,\n",
        "    predictions=None):\n",
        "  \"\"\"\n",
        "  Plot traing data,\n",
        "  test data ,\n",
        "  compares Predication\n",
        "  \"\"\"\n",
        "  plt.figure(figsize=(10,7))\n",
        "  ##Plot  traing data in blue color\n",
        "  plt.scatter(\n",
        "      train_data,\n",
        "      train_labels,\n",
        "      c=\"b\",\n",
        "      s=4,\n",
        "      label=\"Training data\"\n",
        "\n",
        "  )\n",
        "\n",
        "  ##Plot test data in green\n",
        "  plt.scatter(\n",
        "      train_data,\n",
        "      train_labels,\n",
        "      c='g',\n",
        "      s=4,\n",
        "      label=\"Testing data\"\n",
        "  )\n",
        "  ##Prediction\n",
        "  if predictions is not None:\n",
        "    plt.scatter(test_data,\n",
        "              predictions,\n",
        "              c='r',\n",
        "              s=4,\n",
        "              label=\"Predictions\"\n",
        "              )\n",
        "    plt.legend(prop={\"size\":14})\n",
        "plot_prediction();\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "8kJcwimL1zXe",
        "outputId": "d8297121-decc-4f11-93d2-68b5686a2e05"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cTB-DHi86Uuo"
      }
    }
  ]
}